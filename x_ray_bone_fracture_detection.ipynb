{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import datetime\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data-set loading and Pre-processing\n",
    "Data-set link: https://mega.nz/file/zcdywLhI#fck4ufXy_o_Uiu0vGqh-cZiKHw5Xe_n4M2qWUWSheAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the dataset folders\n",
    "train_data_dir = 'archive (6)/train'\n",
    "test_data_dir = 'archive (6)/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 15\n",
    "# Set the input image dimensions\n",
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8863 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an ImageDataGenerator for data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,        # Normalize pixel values between 0 and 1\n",
    "    shear_range=0.2,        # Apply random shear transformations\n",
    "    zoom_range=0.2,         # Apply random zoom transformations\n",
    "    horizontal_flip=True)  # Flip images horizontally\n",
    "\n",
    "\n",
    "# Only normalize pixel values for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Load and augment training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "# Load and normalize testing data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               22429824  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22430849 (85.57 MB)\n",
      "Trainable params: 22430849 (85.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                           input_shape=(img_width, img_height, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "277/277 [==============================] - 84s 301ms/step - loss: 0.7126 - accuracy: 0.5894\n",
      "Epoch 2/15\n",
      "277/277 [==============================] - 75s 271ms/step - loss: 0.6283 - accuracy: 0.6317\n",
      "Epoch 3/15\n",
      "277/277 [==============================] - 74s 268ms/step - loss: 0.6143 - accuracy: 0.6445\n",
      "Epoch 4/15\n",
      "277/277 [==============================] - 72s 259ms/step - loss: 0.5943 - accuracy: 0.6628\n",
      "Epoch 5/15\n",
      "277/277 [==============================] - 79s 282ms/step - loss: 0.5770 - accuracy: 0.6839\n",
      "Epoch 6/15\n",
      "277/277 [==============================] - 69s 250ms/step - loss: 0.5555 - accuracy: 0.7079\n",
      "Epoch 7/15\n",
      "277/277 [==============================] - 69s 248ms/step - loss: 0.5419 - accuracy: 0.7207\n",
      "Epoch 8/15\n",
      "277/277 [==============================] - 67s 243ms/step - loss: 0.5236 - accuracy: 0.7418\n",
      "Epoch 9/15\n",
      "277/277 [==============================] - 69s 249ms/step - loss: 0.5053 - accuracy: 0.7530\n",
      "Epoch 10/15\n",
      "277/277 [==============================] - 67s 240ms/step - loss: 0.4892 - accuracy: 0.7667\n",
      "Epoch 11/15\n",
      "277/277 [==============================] - 66s 237ms/step - loss: 0.4693 - accuracy: 0.7784\n",
      "Epoch 12/15\n",
      "277/277 [==============================] - 66s 237ms/step - loss: 0.4397 - accuracy: 0.7974\n",
      "Epoch 13/15\n",
      "277/277 [==============================] - 66s 238ms/step - loss: 0.4084 - accuracy: 0.8169\n",
      "Epoch 14/15\n",
      "277/277 [==============================] - 69s 249ms/step - loss: 0.3714 - accuracy: 0.8338\n",
      "Epoch 15/15\n",
      "277/277 [==============================] - 73s 262ms/step - loss: 0.3380 - accuracy: 0.8493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x308c83a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, epochs=epochs, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('x_ray.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deployment using Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('x_ray.keras')\n",
    "\n",
    "# Define the function for image classification\n",
    "def classify_image(img):\n",
    "    # Set the input image dimensions\n",
    "    img_width, img_height = 150, 150\n",
    "\n",
    "    # Resize the image to match the model's input shape\n",
    "    img = img.resize((img_width, img_height))\n",
    "\n",
    "    # Convert the image to a numpy array\n",
    "    img = np.array(img)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Get the prediction\n",
    "    prediction = model.predict(img)\n",
    "\n",
    "    return \"NOT fractured\" if prediction > 0.5 else \"fractured\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.28.3, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=classify_image,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload an X-ray image\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Bone Fracture Classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    }
   ],
   "source": [
    "# Start the Gradio interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
